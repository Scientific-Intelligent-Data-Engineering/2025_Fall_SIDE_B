{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "c0UeUb9VFkpw",
        "outputId": "53e5a129-ebe9-4e4c-cda0-95ca8eb7ea16"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_mnist' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3125909483.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_mnist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50_000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mnist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50_000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_mnist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50_000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60_000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mnist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50_000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60_000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_mnist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60_000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mnist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60_000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_mnist' is not defined"
          ]
        }
      ],
      "source": [
        "X_train, y_train = X_mnist[:50_000], y_mnist[:50_000]\n",
        "X_valid, y_valid = X_mnist[50_000:60_000], y_mnist[50_000:60_000]\n",
        "X_test, y_test = X_mnist[60_000:], y_mnist[60_000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qgCQatmFua9"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8OQlia1Gbtp",
        "outputId": "d518952b-acec-45e9-9789-b4634842ffd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ExtraTrees valid acc : 0.9701\n",
            "LinearSVC valid acc  : 0.9136\n",
            "MLP valid acc        : 0.9754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voting valid acc     : 0.971\n",
            "\n",
            "--- Test Accuracy ---\n",
            "ExtraTrees : 0.9712\n",
            "LinearSVC  : 0.9159\n",
            "MLP        : 0.9749\n",
            "Voting     : 0.9687\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# 1) Keras에서 MNIST 로드\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 2) (n_samples, 28*28) 형태로 평탄화 + float 변환\n",
        "X_train_full = X_train_full.reshape(-1, 28*28).astype(np.float32) / 255.0\n",
        "X_test       = X_test.reshape(-1, 28*28).astype(np.float32) / 255.0\n",
        "y_train_full = y_train_full.astype(np.int8)\n",
        "y_test       = y_test.astype(np.int8)\n",
        "\n",
        "# 3) train 50,000 / valid 10,000 으로 다시 나누기\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full,\n",
        "    test_size=10000, random_state=42, stratify=y_train_full\n",
        ")\n",
        "\n",
        "\n",
        "# 3) 개별 모델 정의\n",
        "clf1 = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "clf2 = LinearSVC(max_iter=2000)\n",
        "clf3 = MLPClassifier(hidden_layer_sizes=(100,), max_iter=20, random_state=42)\n",
        "\n",
        "# 4) 개별 모델 학습\n",
        "clf1.fit(X_train, y_train)\n",
        "clf2.fit(X_train, y_train)\n",
        "clf3.fit(X_train, y_train)\n",
        "\n",
        "# 5) 검증 세트에서 각 모델 정확도 비교\n",
        "valid_pred1 = clf1.predict(X_valid)\n",
        "valid_pred2 = clf2.predict(X_valid)\n",
        "valid_pred3 = clf3.predict(X_valid)\n",
        "\n",
        "print(\"ExtraTrees valid acc :\", accuracy_score(y_valid, valid_pred1))\n",
        "print(\"LinearSVC valid acc  :\", accuracy_score(y_valid, valid_pred2))\n",
        "print(\"MLP valid acc        :\", accuracy_score(y_valid, valid_pred3))\n",
        "\n",
        "# 6) Voting Classifier (Hard Voting)\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('extra', clf1),\n",
        "        ('svc', clf2),\n",
        "        ('mlp', clf3)\n",
        "    ],\n",
        "    voting='hard'\n",
        ")\n",
        "\n",
        "# Voting 학습\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# 7) 검증 세트 성능\n",
        "valid_pred_vote = voting_clf.predict(X_valid)\n",
        "print(\"Voting valid acc     :\", accuracy_score(y_valid, valid_pred_vote))\n",
        "\n",
        "# 8) 최종 Test 세트 성능 비교\n",
        "test_pred1 = clf1.predict(X_test)\n",
        "test_pred2 = clf2.predict(X_test)\n",
        "test_pred3 = clf3.predict(X_test)\n",
        "test_pred_vote = voting_clf.predict(X_test)\n",
        "\n",
        "print(\"\\n--- Test Accuracy ---\")\n",
        "print(\"ExtraTrees :\", accuracy_score(y_test, test_pred1))\n",
        "print(\"LinearSVC  :\", accuracy_score(y_test, test_pred2))\n",
        "print(\"MLP        :\", accuracy_score(y_test, test_pred3))\n",
        "print(\"Voting     :\", accuracy_score(y_test, test_pred_vote))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_kFkmJgQ9A5"
      },
      "source": [
        "voting이 더 떨어져서 soft방법으로 해보기로 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eTlipUeT4xw",
        "outputId": "8ac9186f-6f8b-4bdf-b42c-2c64f9a2daf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (15000, 784) Valid: (5000, 784) Test: (10000, 784)\n",
            "\n",
            "[Train] ExtraTrees\n",
            "\n",
            "[Train] MLP\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Validation Accuracy (single models) ===\n",
            "ExtraTrees : 0.9614\n",
            "MLP        : 0.948\n",
            "\n",
            "[Train] Soft Voting (ET + MLP)\n",
            "\n",
            "=== Validation Accuracy (Soft Voting) ===\n",
            "Soft Voting : 0.9544\n",
            "\n",
            "=== Test Accuracy ===\n",
            "ExtraTrees : 0.958\n",
            "MLP        : 0.9559\n",
            "SoftVote   : 0.9602\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. MNIST 로드 & 전처리\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train_full = X_train_full.reshape(-1, 28*28).astype(np.float32) / 255.0\n",
        "X_test       = X_test.reshape(-1, 28*28).astype(np.float32) / 255.0\n",
        "y_train_full = y_train_full.astype(np.int8)\n",
        "y_test       = y_test.astype(np.int8)\n",
        "\n",
        "# ---- 옵션: 학습을 빠르게 하려면 train 일부만 사용 (예: 20,000개) ----\n",
        "X_train_sub, _, y_train_sub, _ = train_test_split(\n",
        "    X_train_full, y_train_full,\n",
        "    train_size=20000, random_state=42, stratify=y_train_full\n",
        ")\n",
        "X_train = X_train_sub\n",
        "y_train = y_train_sub\n",
        "\n",
        "# 검증용으로 10,000개 따로 떼고 싶으면:\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train, y_train,\n",
        "    test_size=5000, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"Valid:\", X_valid.shape, \"Test:\", X_test.shape)\n",
        "\n",
        "# 2. 개별 분류기 (둘 다 predict_proba 지원 → soft voting 가능)\n",
        "clf_et = ExtraTreesClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "clf_mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(100,),  # 작게 잡아서 속도↑\n",
        "    max_iter=20,                # epoch 줄이기\n",
        "    alpha=1e-4,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 3. 개별 모델 학습\n",
        "print(\"\\n[Train] ExtraTrees\")\n",
        "clf_et.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n[Train] MLP\")\n",
        "clf_mlp.fit(X_train, y_train)\n",
        "\n",
        "# 4. 검증 세트에서 단일 모델 성능\n",
        "valid_pred_et  = clf_et.predict(X_valid)\n",
        "valid_pred_mlp = clf_mlp.predict(X_valid)\n",
        "\n",
        "print(\"\\n=== Validation Accuracy (single models) ===\")\n",
        "print(\"ExtraTrees :\", accuracy_score(y_valid, valid_pred_et))\n",
        "print(\"MLP        :\", accuracy_score(y_valid, valid_pred_mlp))\n",
        "\n",
        "# 5. Soft Voting 앙상블 (ExtraTrees + MLP)\n",
        "voting_soft = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('et',  clf_et),\n",
        "        ('mlp', clf_mlp)\n",
        "    ],\n",
        "    voting='soft',      # 확률 평균\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\n[Train] Soft Voting (ET + MLP)\")\n",
        "voting_soft.fit(X_train, y_train)\n",
        "\n",
        "# 6. 검증 세트 성능\n",
        "valid_pred_vote = voting_soft.predict(X_valid)\n",
        "print(\"\\n=== Validation Accuracy (Soft Voting) ===\")\n",
        "print(\"Soft Voting :\", accuracy_score(y_valid, valid_pred_vote))\n",
        "\n",
        "# 7. 테스트 성능\n",
        "test_pred_et   = clf_et.predict(X_test)\n",
        "test_pred_mlp  = clf_mlp.predict(X_test)\n",
        "test_pred_vote = voting_soft.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Test Accuracy ===\")\n",
        "print(\"ExtraTrees :\", accuracy_score(y_test, test_pred_et))\n",
        "print(\"MLP        :\", accuracy_score(y_test, test_pred_mlp))\n",
        "print(\"SoftVote   :\", accuracy_score(y_test, test_pred_vote))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njK1E0FwQ53r",
        "outputId": "fd66a43a-77e1-43c2-cb86-7e1be7984804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (50000, 784) Valid: (10000, 784) Test: (10000, 784)\n",
            "\n",
            "[Train] ExtraTrees\n",
            "\n",
            "[Train] SVC (probability=True)\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# 0. 라이브러리 임포트\n",
        "# ================================\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ================================\n",
        "# 1. MNIST 데이터 로드 & 전처리\n",
        "# ================================\n",
        "# (X_train_full, y_train_full): 60,000\n",
        "# (X_test, y_test): 10,000\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# (N, 28, 28) -> (N, 784) + 정규화\n",
        "X_train_full = X_train_full.reshape(-1, 28 * 28).astype(np.float32) / 255.0\n",
        "X_test       = X_test.reshape(-1, 28 * 28).astype(np.float32) / 255.0\n",
        "y_train_full = y_train_full.astype(np.int8)\n",
        "y_test       = y_test.astype(np.int8)\n",
        "\n",
        "# train 50,000 / valid 10,000으로 분리\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full,\n",
        "    y_train_full,\n",
        "    test_size=10000,\n",
        "    random_state=42,\n",
        "    stratify=y_train_full\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"Valid:\", X_valid.shape, \"Test:\", X_test.shape)\n",
        "\n",
        "# ================================\n",
        "# 2. 개별 분류기 정의\n",
        "# ================================\n",
        "# 1) ExtraTrees (랜덤 포레스트 계열)\n",
        "clf_et = ExtraTreesClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 2) SVC (확률 출력 가능하도록 probability=True)\n",
        "#   - LinearSVC는 predict_proba가 없어서 soft voting 불가 → SVC로 교체\n",
        "clf_svc = SVC(\n",
        "    kernel='linear',        # 과부하되면 'linear' 유지, 더 높이고 싶으면 'rbf'로 실험\n",
        "    probability=True,       # soft voting을 위해 필수\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 3) MLP (간단한 신경망)\n",
        "clf_mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(100,),\n",
        "    max_iter=30,            # 필요하면 늘리기\n",
        "    alpha=1e-4,\n",
        "    random_state=42,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# 3. 개별 모델 학습\n",
        "# ================================\n",
        "print(\"\\n[Train] ExtraTrees\")\n",
        "clf_et.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n[Train] SVC (probability=True)\")\n",
        "clf_svc.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n[Train] MLP\")\n",
        "clf_mlp.fit(X_train, y_train)\n",
        "\n",
        "# ================================\n",
        "# 4. 검증 세트에서 개별 성능 확인\n",
        "# ================================\n",
        "valid_pred_et  = clf_et.predict(X_valid)\n",
        "valid_pred_svc = clf_svc.predict(X_valid)\n",
        "valid_pred_mlp = clf_mlp.predict(X_valid)\n",
        "\n",
        "print(\"\\n=== Validation Accuracy (single models) ===\")\n",
        "print(\"ExtraTrees :\", accuracy_score(y_valid, valid_pred_et))\n",
        "print(\"SVC        :\", accuracy_score(y_valid, valid_pred_svc))\n",
        "print(\"MLP        :\", accuracy_score(y_valid, valid_pred_mlp))\n",
        "\n",
        "# ================================\n",
        "# 5. Soft Voting 앙상블 정의 & 학습\n",
        "# ================================\n",
        "voting_soft = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('et',  clf_et),\n",
        "        ('svc', clf_svc),\n",
        "        ('mlp', clf_mlp)\n",
        "    ],\n",
        "    voting='soft',          # <-- 핵심: soft voting\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\n[Train] Soft VotingClassifier\")\n",
        "voting_soft.fit(X_train, y_train)\n",
        "\n",
        "# ================================\n",
        "# 6. 검증 세트에서 soft voting 성능\n",
        "# ================================\n",
        "valid_pred_vote = voting_soft.predict(X_valid)\n",
        "print(\"\\n=== Validation Accuracy (Soft Voting) ===\")\n",
        "print(\"Soft Voting :\", accuracy_score(y_valid, valid_pred_vote))\n",
        "\n",
        "# ================================\n",
        "# 7. 최종 Test 세트 성능 비교\n",
        "# ================================\n",
        "test_pred_et    = clf_et.predict(X_test)\n",
        "test_pred_svc   = clf_svc.predict(X_test)\n",
        "test_pred_mlp   = clf_mlp.predict(X_test)\n",
        "test_pred_vote  = voting_soft.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Test Accuracy ===\")\n",
        "print(\"ExtraTrees :\", accuracy_score(y_test, test_pred_et))\n",
        "print(\"SVC        :\", accuracy_score(y_test, test_pred_svc))\n",
        "print(\"MLP        :\", accuracy_score(y_test, test_pred_mlp))\n",
        "print(\"SoftVote   :\", accuracy_score(y_test, test_pred_vote))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "sHyyft7zSL1N",
        "outputId": "f0b99aee-7d57-4675-9ad9-c4815de6725e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (60000, 784) Test: (10000, 784)\n",
            "\n",
            "[Train] StackingClassifier\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1071207295.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# ==========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[Train] StackingClassifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mstack_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# ==========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sample_weight\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     @available_if(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             predictions = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    255\u001b[0m                 delayed(cross_val_predict)(\n\u001b[1;32m    256\u001b[0m                     \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 0. 라이브러리 임포트\n",
        "# ==========================================\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ==========================================\n",
        "# 1. MNIST 데이터 로드 & 전처리\n",
        "# ==========================================\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train_full = X_train_full.reshape(-1, 28*28).astype(np.float32) / 255.0\n",
        "X_test       = X_test.reshape(-1, 28*28).astype(np.float32) / 255.0\n",
        "y_train_full = y_train_full.astype(np.int8)\n",
        "y_test       = y_test.astype(np.int8)\n",
        "\n",
        "print(\"Train:\", X_train_full.shape, \"Test:\", X_test.shape)\n",
        "\n",
        "# ==========================================\n",
        "# 2. 개별 기본 모델(base estimators)\n",
        "# ==========================================\n",
        "clf_et = ExtraTreesClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "clf_svc = SVC(\n",
        "    kernel='linear',\n",
        "    probability=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "clf_mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(100,),\n",
        "    max_iter=30,\n",
        "    alpha=1e-4,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 3. StackingClassifier 구성\n",
        "# ==========================================\n",
        "\n",
        "estimators = [\n",
        "    ('et', clf_et),\n",
        "    ('svc', clf_svc),\n",
        "    ('mlp', clf_mlp),\n",
        "]\n",
        "\n",
        "meta_model = LogisticRegression(max_iter=200)\n",
        "\n",
        "stack_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=meta_model,\n",
        "    stack_method='predict_proba',  # 확률 기반 스태킹\n",
        "    n_jobs=-1,\n",
        "    passthrough=False              # 기본 모델 입력 피쳐를 메타 모델에 전달하지 않음\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 4. 스태킹 모델 학습\n",
        "# ==========================================\n",
        "print(\"\\n[Train] StackingClassifier\")\n",
        "stack_clf.fit(X_train_full, y_train_full)\n",
        "\n",
        "# ==========================================\n",
        "# 5. 테스트 성능 평가\n",
        "# ==========================================\n",
        "test_pred_stack = stack_clf.predict(X_test)\n",
        "acc_stack = accuracy_score(y_test, test_pred_stack)\n",
        "\n",
        "print(\"\\n=== Test Accuracy ===\")\n",
        "print(\"Stacking :\", acc_stack)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 0. 라이브러리 임포트\n",
        "# ==========================================\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier, StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ==========================================\n",
        "# 1. MNIST 데이터 로드 & 전처리\n",
        "# ==========================================\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train_full = X_train_full.reshape(-1, 28*28).astype(np.float32) / 255.0\n",
        "X_test       = X_test.reshape(-1, 28*28).astype(np.float32) / 255.0\n",
        "y_train_full = y_train_full.astype(np.int8)\n",
        "y_test       = y_test.astype(np.int8)\n",
        "\n",
        "print(\"Full Train:\", X_train_full.shape, \"Test:\", X_test.shape)\n",
        "\n",
        "# ---- (1) 학습 속도용: train 일부만 사용 (예: 20,000개) ----\n",
        "X_train_sub, _, y_train_sub, _ = train_test_split(\n",
        "    X_train_full, y_train_full,\n",
        "    train_size=20000,       # 필요하면 15000, 30000 등으로 조절\n",
        "    random_state=42,\n",
        "    stratify=y_train_full\n",
        ")\n",
        "\n",
        "print(\"Used Train subset:\", X_train_sub.shape)\n",
        "\n",
        "# ==========================================\n",
        "# 2. 개별 기본 모델(base estimators)\n",
        "# ==========================================\n",
        "clf_et = ExtraTreesClassifier(\n",
        "    n_estimators=50,         # (2) 트리 개수 줄여서 속도↓\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "clf_svc = SVC(\n",
        "    kernel='linear',\n",
        "    probability=True,        # 스태킹에서 predict_proba 사용\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "clf_mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(100,),\n",
        "    max_iter=15,             # (2) epoch 줄여서 속도↓\n",
        "    alpha=1e-4,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 3. StackingClassifier 구성\n",
        "# ==========================================\n",
        "estimators = [\n",
        "    ('et',  clf_et),\n",
        "    ('svc', clf_svc),\n",
        "    ('mlp', clf_mlp),\n",
        "]\n",
        "\n",
        "meta_model = LogisticRegression(max_iter=200)\n",
        "\n",
        "stack_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=meta_model,\n",
        "    stack_method='predict_proba',  # 확률 기반 스태킹\n",
        "    n_jobs=-1,\n",
        "    passthrough=False,\n",
        "    cv=3                           # (3) 기본 5-fold → 3-fold 로 줄여서 속도↓\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 4. 스태킹 모델 학습\n",
        "# ==========================================\n",
        "print(\"\\n[Train] StackingClassifier (subset + 3-fold CV)\")\n",
        "stack_clf.fit(X_train_sub, y_train_sub)\n",
        "\n",
        "# ==========================================\n",
        "# 5. 테스트 성능 평가\n",
        "# ==========================================\n",
        "test_pred_stack = stack_clf.predict(X_test)\n",
        "acc_stack = accuracy_score(y_test, test_pred_stack)\n",
        "\n",
        "print(\"\\n=== Test Accuracy ===\")\n",
        "print(\"Stacking :\", acc_stack)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsUi9MqbnSrS",
        "outputId": "44065d28-3f71-4c6b-e940-6bf4c75ce01b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Train: (60000, 784) Test: (10000, 784)\n",
            "Used Train subset: (20000, 784)\n",
            "\n",
            "[Train] StackingClassifier (subset + 3-fold CV)\n",
            "\n",
            "=== Test Accuracy ===\n",
            "Stacking : 0.9678\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}